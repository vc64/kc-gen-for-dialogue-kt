No conda package cache directories found outside your home directory. To
prevent conda from filling up your home directory, you can create a new
directory at `/work/pi_<your_pi_name>/$USER/.conda/pkgs` and reload the module. 
No conda environment directories found outside your home directory. To prevent
conda from filling up your home directory, you can create a new directory at
`/work/pi_<your_pi_name>/$USER/.conda/envs` and reload the module. 
Loading conda version miniforge3-24.7.1
Loading cuda version 12.6
Loading cudnn version 8.9.7.29-12
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:08<00:25,  8.54s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.63s/it]
Traceback (most recent call last):
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/main.py", line 71, in <module>
    main()
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/main.py", line 68, in main
    args.func(args)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/training.py", line 127, in train
    return crossval(args, fn)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/training.py", line 92, in crossval
    metrics = fn(args, fold)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/training.py", line 227, in train_lmkt
    model, tokenizer = get_model(args.base_model, False, pt_model_name=args.pt_model_name, r=args.r, lora_alpha=args.lora_alpha, quantize=args.quantize)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/models/lm.py", line 31, in get_model
    model = get_base_model(base_model_name, tokenizer, quantize)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/models/lm.py", line 13, in get_base_model
    base_model = AutoModelForCausalLM.from_pretrained(
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4015, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/accelerate/big_modeling.py", line 502, in dispatch_model
    model.to(device)
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/transformers/modeling_utils.py", line 2861, in to
    raise ValueError(
ValueError: `.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`.
