Removing conda version miniforge3-24.7.1
No conda package cache directories found outside your home directory. To
prevent conda from filling up your home directory, you can create a new
directory at `/work/pi_<your_pi_name>/$USER/.conda/pkgs` and reload the module. 
No conda environment directories found outside your home directory. To prevent
conda from filling up your home directory, you can create a new directory at
`/work/pi_<your_pi_name>/$USER/.conda/envs` and reload the module. 
Loading conda version miniforge3-24.7.1
Removing cuda version 12.6
Loading cuda version 12.6
Loading cudnn version 8.9.7.29-12
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:45, 15.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:26<00:25, 12.81s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:36<00:11, 11.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:36<00:00,  7.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:36<00:00,  9.25s/it]
Training:   0%|          | 0/4936 [00:00<?, ?it/s]/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:101: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:304.)
  freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/bitsandbytes/backends/default/ops.py:68: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:304.)
  output = output.addmm(subA, subB)
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/nn/modules/linear.py:134: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:304.)
  return F.linear(input, self.weight, self.bias)
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:290: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:304.)
  grad_A = torch.matmul(grad_output.to(ctx.dtype_A), CB).view(ctx.grad_shape)
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/autograd/graph.py:841: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:304.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/autograd/graph.py:841: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at /pytorch/aten/src/ATen/native/transformers/cuda/attention_backward.cu:897.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Training:   0%|          | 1/4936 [00:03<5:22:59,  3.93s/it]Training:   0%|          | 2/4936 [00:05<3:37:35,  2.65s/it]Training:   0%|          | 3/4936 [00:07<3:01:31,  2.21s/it]Training:   0%|          | 4/4936 [00:08<2:41:26,  1.96s/it]Training:   0%|          | 5/4936 [00:10<2:32:41,  1.86s/it]Training:   0%|          | 6/4936 [00:12<2:36:26,  1.90s/it]Training:   0%|          | 7/4936 [00:14<2:29:40,  1.82s/it]Training:   0%|          | 8/4936 [00:16<2:42:35,  1.98s/it]Training:   0%|          | 9/4936 [00:18<2:32:53,  1.86s/it]Training:   0%|          | 10/4936 [00:20<2:46:33,  2.03s/it]Training:   0%|          | 11/4936 [00:21<2:30:02,  1.83s/it]Training:   0%|          | 12/4936 [00:25<3:08:19,  2.29s/it]Training:   0%|          | 13/4936 [00:27<3:09:44,  2.31s/it]Training:   0%|          | 14/4936 [00:30<3:10:19,  2.32s/it]Training:   0%|          | 15/4936 [00:31<2:52:37,  2.10s/it]Training:   0%|          | 16/4936 [00:33<2:41:23,  1.97s/it]Training:   0%|          | 17/4936 [00:35<2:38:55,  1.94s/it]Training:   0%|          | 18/4936 [00:37<2:37:23,  1.92s/it]Training:   0%|          | 19/4936 [00:38<2:31:30,  1.85s/it]Training:   0%|          | 20/4936 [00:40<2:29:00,  1.82s/it]Training:   0%|          | 21/4936 [00:42<2:25:30,  1.78s/it]Training:   0%|          | 22/4936 [00:43<2:10:39,  1.60s/it]Training:   0%|          | 23/4936 [00:45<2:17:12,  1.68s/it]Training:   0%|          | 24/4936 [00:46<2:19:10,  1.70s/it]Training:   1%|          | 25/4936 [00:49<2:36:55,  1.92s/it]Training:   1%|          | 26/4936 [00:51<2:52:44,  2.11s/it]Training:   1%|          | 27/4936 [00:53<2:37:38,  1.93s/it]Training:   1%|          | 28/4936 [00:55<2:45:49,  2.03s/it]Training:   1%|          | 29/4936 [00:57<2:43:46,  2.00s/it]Training:   1%|          | 30/4936 [00:59<2:31:16,  1.85s/it]Training:   1%|          | 31/4936 [01:00<2:21:09,  1.73s/it]Training:   1%|          | 32/4936 [01:04<3:19:32,  2.44s/it]Training:   1%|          | 33/4936 [01:06<3:06:44,  2.29s/it]Training:   1%|          | 34/4936 [01:08<2:46:55,  2.04s/it]Training:   1%|          | 35/4936 [01:10<2:52:34,  2.11s/it]Training:   1%|          | 36/4936 [01:12<2:47:00,  2.04s/it]Training:   1%|          | 37/4936 [01:13<2:37:29,  1.93s/it]Training:   1%|          | 38/4936 [01:15<2:39:38,  1.96s/it]Training:   1%|          | 39/4936 [01:17<2:37:39,  1.93s/it]Training:   1%|          | 40/4936 [01:19<2:25:44,  1.79s/it]Training:   1%|          | 41/4936 [01:21<2:30:26,  1.84s/it]Training:   1%|          | 42/4936 [01:23<2:31:07,  1.85s/it]Training:   1%|          | 43/4936 [01:24<2:19:14,  1.71s/it]Training:   1%|          | 44/4936 [01:26<2:36:29,  1.92s/it]Training:   1%|          | 45/4936 [01:28<2:32:40,  1.87s/it]Training:   1%|          | 46/4936 [01:30<2:27:23,  1.81s/it]Training:   1%|          | 47/4936 [01:31<2:24:01,  1.77s/it]Training:   1%|          | 48/4936 [01:33<2:29:13,  1.83s/it]Training:   1%|          | 49/4936 [01:35<2:23:16,  1.76s/it]Training:   1%|          | 50/4936 [01:36<2:16:30,  1.68s/it]Training:   1%|          | 51/4936 [01:39<2:47:53,  2.06s/it]Training:   1%|          | 52/4936 [01:41<2:45:34,  2.03s/it]Training:   1%|          | 53/4936 [01:43<2:45:20,  2.03s/it]Training:   1%|          | 54/4936 [01:45<2:32:08,  1.87s/it]Training:   1%|          | 55/4936 [01:47<2:28:58,  1.83s/it]Training:   1%|          | 56/4936 [01:49<2:39:32,  1.96s/it]Training:   1%|          | 57/4936 [01:51<2:37:43,  1.94s/it]Training:   1%|          | 58/4936 [01:53<2:54:20,  2.14s/it]Training:   1%|          | 59/4936 [01:59<4:07:59,  3.05s/it]Training:   1%|          | 60/4936 [02:00<3:37:56,  2.68s/it]Training:   1%|          | 61/4936 [02:03<3:29:07,  2.57s/it]Training:   1%|▏         | 62/4936 [02:05<3:13:39,  2.38s/it]Training:   1%|▏         | 63/4936 [02:08<3:43:38,  2.75s/it]Training:   1%|▏         | 64/4936 [02:11<3:53:19,  2.87s/it]Training:   1%|▏         | 65/4936 [02:13<3:21:32,  2.48s/it]Training:   1%|▏         | 66/4936 [02:15<3:06:42,  2.30s/it]Training:   1%|▏         | 67/4936 [02:17<2:59:22,  2.21s/it]Training:   1%|▏         | 68/4936 [02:18<2:38:58,  1.96s/it]Training:   1%|▏         | 69/4936 [02:20<2:29:33,  1.84s/it]Training:   1%|▏         | 70/4936 [02:22<2:25:23,  1.79s/it]Training:   1%|▏         | 71/4936 [02:24<2:43:44,  2.02s/it]Training:   1%|▏         | 72/4936 [02:26<2:37:24,  1.94s/it]Training:   1%|▏         | 73/4936 [02:28<2:32:47,  1.89s/it]Training:   1%|▏         | 74/4936 [02:29<2:23:04,  1.77s/it]Training:   2%|▏         | 75/4936 [02:30<2:12:22,  1.63s/it]Training:   2%|▏         | 76/4936 [02:32<2:20:51,  1.74s/it]Training:   2%|▏         | 77/4936 [02:34<2:17:32,  1.70s/it]Training:   2%|▏         | 78/4936 [02:36<2:21:42,  1.75s/it]Training:   2%|▏         | 79/4936 [02:38<2:24:44,  1.79s/it]Training:   2%|▏         | 80/4936 [02:40<2:36:34,  1.93s/it]Training:   2%|▏         | 81/4936 [02:41<2:22:38,  1.76s/it]Training:   2%|▏         | 82/4936 [02:45<3:19:16,  2.46s/it]Training:   2%|▏         | 83/4936 [02:47<2:53:38,  2.15s/it]Training:   2%|▏         | 84/4936 [02:49<2:49:47,  2.10s/it]Training:   2%|▏         | 85/4936 [02:51<2:39:49,  1.98s/it]Training:   2%|▏         | 86/4936 [02:53<2:55:11,  2.17s/it]Training:   2%|▏         | 87/4936 [02:55<2:41:43,  2.00s/it]Training:   2%|▏         | 88/4936 [02:57<2:56:28,  2.18s/it]Training:   2%|▏         | 89/4936 [02:59<2:39:52,  1.98s/it]Training:   2%|▏         | 90/4936 [03:01<2:53:49,  2.15s/it]Training:   2%|▏         | 91/4936 [03:03<2:44:36,  2.04s/it]Training:   2%|▏         | 92/4936 [03:05<2:43:21,  2.02s/it]Training:   2%|▏         | 93/4936 [03:08<2:50:45,  2.12s/it]Training:   2%|▏         | 94/4936 [03:09<2:45:05,  2.05s/it]Training:   2%|▏         | 95/4936 [03:11<2:35:09,  1.92s/it]Training:   2%|▏         | 96/4936 [03:13<2:33:50,  1.91s/it]Training:   2%|▏         | 97/4936 [03:15<2:26:10,  1.81s/it]Training:   2%|▏         | 98/4936 [03:16<2:22:26,  1.77s/it]Training:   2%|▏         | 99/4936 [03:18<2:24:55,  1.80s/it]Training:   2%|▏         | 100/4936 [03:21<2:53:19,  2.15s/it]Training:   2%|▏         | 101/4936 [03:23<2:42:26,  2.02s/it]Training:   2%|▏         | 102/4936 [03:24<2:33:42,  1.91s/it]Training:   2%|▏         | 103/4936 [03:27<2:42:36,  2.02s/it]Training:   2%|▏         | 104/4936 [03:28<2:26:40,  1.82s/it]Training:   2%|▏         | 105/4936 [03:30<2:29:04,  1.85s/it]Training:   2%|▏         | 106/4936 [03:32<2:22:48,  1.77s/it]Training:   2%|▏         | 107/4936 [03:33<2:12:31,  1.65s/it]Training:   2%|▏         | 108/4936 [03:35<2:31:20,  1.88s/it]Training:   2%|▏         | 109/4936 [03:37<2:19:15,  1.73s/it]Training:   2%|▏         | 110/4936 [03:38<2:13:07,  1.66s/it]Training:   2%|▏         | 111/4936 [03:42<3:00:33,  2.25s/it]Training:   2%|▏         | 112/4936 [03:43<2:45:31,  2.06s/it]Training:   2%|▏         | 113/4936 [03:46<2:50:18,  2.12s/it]Training:   2%|▏         | 114/4936 [03:48<2:44:40,  2.05s/it]Training:   2%|▏         | 115/4936 [03:50<2:43:13,  2.03s/it]Training:   2%|▏         | 116/4936 [03:51<2:33:48,  1.91s/it]Training:   2%|▏         | 117/4936 [03:53<2:29:47,  1.87s/it]Training:   2%|▏         | 118/4936 [03:55<2:22:56,  1.78s/it]Training:   2%|▏         | 119/4936 [03:57<2:28:41,  1.85s/it]Training:   2%|▏         | 120/4936 [03:58<2:19:51,  1.74s/it]Training:   2%|▏         | 121/4936 [04:00<2:24:22,  1.80s/it]Training:   2%|▏         | 122/4936 [04:02<2:23:19,  1.79s/it]Training:   2%|▏         | 123/4936 [04:03<2:14:58,  1.68s/it]Training:   3%|▎         | 124/4936 [04:05<2:13:35,  1.67s/it]Training:   3%|▎         | 125/4936 [04:07<2:15:36,  1.69s/it]Training:   3%|▎         | 126/4936 [04:08<2:09:28,  1.62s/it]Training:   3%|▎         | 127/4936 [04:10<2:25:03,  1.81s/it]Training:   3%|▎         | 128/4936 [04:13<2:40:31,  2.00s/it]Training:   3%|▎         | 129/4936 [04:14<2:32:06,  1.90s/it]Training:   3%|▎         | 130/4936 [04:17<2:40:54,  2.01s/it]Training:   3%|▎         | 131/4936 [04:19<2:37:48,  1.97s/it]Training:   3%|▎         | 132/4936 [04:20<2:22:58,  1.79s/it]Training:   3%|▎         | 133/4936 [04:21<2:12:40,  1.66s/it]Training:   3%|▎         | 134/4936 [04:23<2:12:32,  1.66s/it]Training:   3%|▎         | 135/4936 [04:28<3:36:00,  2.70s/it]Training:   3%|▎         | 136/4936 [04:29<3:01:06,  2.26s/it]Training:   3%|▎         | 137/4936 [04:31<2:42:06,  2.03s/it]Training:   3%|▎         | 138/4936 [04:32<2:33:31,  1.92s/it]Training:   3%|▎         | 139/4936 [04:35<2:48:30,  2.11s/it]Training:   3%|▎         | 140/4936 [04:36<2:32:50,  1.91s/it]Training:   3%|▎         | 141/4936 [04:38<2:27:06,  1.84s/it]Training:   3%|▎         | 142/4936 [04:39<2:15:16,  1.69s/it]Training:   3%|▎         | 143/4936 [04:41<2:07:01,  1.59s/it]Training:   3%|▎         | 144/4936 [04:43<2:17:06,  1.72s/it]Training:   3%|▎         | 145/4936 [04:44<2:11:32,  1.65s/it]Training:   3%|▎         | 146/4936 [04:50<3:39:23,  2.75s/it]Training:   3%|▎         | 147/4936 [04:51<3:10:49,  2.39s/it]Training:   3%|▎         | 148/4936 [04:53<2:45:55,  2.08s/it]Training:   3%|▎         | 149/4936 [04:54<2:31:21,  1.90s/it]Training:   3%|▎         | 150/4936 [04:56<2:32:11,  1.91s/it]Training:   3%|▎         | 151/4936 [04:58<2:26:50,  1.84s/it]Training:   3%|▎         | 152/4936 [04:59<2:17:23,  1.72s/it]Training:   3%|▎         | 153/4936 [05:01<2:15:35,  1.70s/it]Training:   3%|▎         | 154/4936 [05:02<2:15:05,  1.70s/it]Training:   3%|▎         | 155/4936 [05:04<2:14:06,  1.68s/it]Training:   3%|▎         | 156/4936 [05:06<2:09:09,  1.62s/it]Training:   3%|▎         | 157/4936 [05:07<2:14:58,  1.69s/it]Training:   3%|▎         | 158/4936 [05:09<2:13:38,  1.68s/it]Training:   3%|▎         | 159/4936 [05:11<2:19:42,  1.75s/it]Training:   3%|▎         | 160/4936 [05:14<2:40:10,  2.01s/it]Training:   3%|▎         | 161/4936 [05:16<2:39:56,  2.01s/it]Training:   3%|▎         | 162/4936 [05:17<2:24:12,  1.81s/it]Training:   3%|▎         | 163/4936 [05:18<2:12:58,  1.67s/it]Training:   3%|▎         | 164/4936 [05:21<2:28:15,  1.86s/it]Training:   3%|▎         | 165/4936 [05:22<2:25:48,  1.83s/it]Training:   3%|▎         | 166/4936 [05:24<2:21:57,  1.79s/it]Training:   3%|▎         | 167/4936 [05:25<2:13:52,  1.68s/it]Training:   3%|▎         | 168/4936 [05:27<2:21:03,  1.78s/it]Training:   3%|▎         | 169/4936 [05:30<2:34:17,  1.94s/it]Training:   3%|▎         | 170/4936 [05:32<2:42:14,  2.04s/it]Training:   3%|▎         | 171/4936 [05:34<2:38:19,  1.99s/it]Training:   3%|▎         | 172/4936 [05:35<2:25:16,  1.83s/it]Training:   4%|▎         | 173/4936 [05:37<2:16:04,  1.71s/it]Training:   4%|▎         | 174/4936 [05:38<2:07:30,  1.61s/it]Training:   4%|▎         | 175/4936 [05:40<2:10:45,  1.65s/it]Training:   4%|▎         | 176/4936 [05:41<2:03:50,  1.56s/it]Training:   4%|▎         | 177/4936 [05:43<2:04:31,  1.57s/it]Training:   4%|▎         | 178/4936 [05:45<2:14:28,  1.70s/it]Training:   4%|▎         | 179/4936 [05:46<2:05:59,  1.59s/it]Training:   4%|▎         | 180/4936 [05:48<2:03:12,  1.55s/it]Training:   4%|▎         | 181/4936 [05:49<2:07:47,  1.61s/it]Training:   4%|▎         | 182/4936 [05:51<2:04:43,  1.57s/it]Training:   4%|▎         | 183/4936 [05:52<2:02:16,  1.54s/it]Training:   4%|▎         | 184/4936 [05:54<2:04:54,  1.58s/it]Training:   4%|▎         | 185/4936 [05:55<1:59:47,  1.51s/it]Training:   4%|▍         | 186/4936 [05:57<2:03:44,  1.56s/it]Training:   4%|▍         | 187/4936 [06:01<2:52:52,  2.18s/it]Training:   4%|▍         | 188/4936 [06:03<2:49:02,  2.14s/it]Training:   4%|▍         | 189/4936 [06:05<2:43:01,  2.06s/it]Training:   4%|▍         | 190/4936 [06:06<2:35:37,  1.97s/it]Training:   4%|▍         | 191/4936 [06:09<2:52:48,  2.19s/it]Training:   4%|▍         | 192/4936 [06:11<2:49:26,  2.14s/it]Training:   4%|▍         | 193/4936 [06:13<2:35:49,  1.97s/it]Training:   4%|▍         | 194/4936 [06:15<2:34:50,  1.96s/it]Training:   4%|▍         | 195/4936 [06:16<2:26:05,  1.85s/it]Training:   4%|▍         | 196/4936 [06:18<2:16:27,  1.73s/it]Training:   4%|▍         | 197/4936 [06:19<2:07:38,  1.62s/it]Training:   4%|▍         | 198/4936 [06:23<2:55:55,  2.23s/it]Training:   4%|▍         | 199/4936 [06:24<2:43:56,  2.08s/it]Training:   4%|▍         | 200/4936 [06:26<2:26:29,  1.86s/it]Training:   4%|▍         | 201/4936 [06:27<2:17:19,  1.74s/it]Training:   4%|▍         | 202/4936 [06:30<2:33:39,  1.95s/it]Training:   4%|▍         | 203/4936 [06:32<2:32:13,  1.93s/it]Training:   4%|▍         | 204/4936 [06:33<2:18:38,  1.76s/it]Training:   4%|▍         | 205/4936 [06:35<2:15:51,  1.72s/it]Training:   4%|▍         | 206/4936 [06:36<2:16:30,  1.73s/it]Training:   4%|▍         | 207/4936 [06:38<2:17:01,  1.74s/it]Training:   4%|▍         | 208/4936 [06:40<2:32:43,  1.94s/it]Training:   4%|▍         | 209/4936 [06:43<2:40:42,  2.04s/it]Training:   4%|▍         | 210/4936 [06:44<2:26:50,  1.86s/it]Training:   4%|▍         | 211/4936 [06:46<2:29:20,  1.90s/it]Training:   4%|▍         | 212/4936 [06:49<2:41:46,  2.05s/it]Training:   4%|▍         | 213/4936 [06:50<2:33:04,  1.94s/it]Training:   4%|▍         | 214/4936 [06:52<2:26:12,  1.86s/it]Training:   4%|▍         | 215/4936 [06:54<2:21:34,  1.80s/it]Training:   4%|▍         | 216/4936 [06:56<2:35:58,  1.98s/it]Training:   4%|▍         | 217/4936 [06:58<2:37:09,  2.00s/it]Training:   4%|▍         | 218/4936 [07:00<2:31:32,  1.93s/it]Training:   4%|▍         | 219/4936 [07:01<2:20:07,  1.78s/it]Training:   4%|▍         | 220/4936 [07:03<2:15:30,  1.72s/it]Training:   4%|▍         | 221/4936 [07:04<2:08:37,  1.64s/it]Training:   4%|▍         | 222/4936 [07:07<2:33:11,  1.95s/it]Training:   5%|▍         | 223/4936 [07:09<2:27:20,  1.88s/it]Training:   5%|▍         | 224/4936 [07:12<2:52:58,  2.20s/it]Training:   5%|▍         | 225/4936 [07:13<2:36:40,  2.00s/it]Training:   5%|▍         | 226/4936 [07:15<2:35:03,  1.98s/it]Training:   5%|▍         | 227/4936 [07:17<2:25:57,  1.86s/it]Training:   5%|▍         | 228/4936 [07:19<2:39:11,  2.03s/it]Training:   5%|▍         | 229/4936 [07:21<2:38:40,  2.02s/it]Training:   5%|▍         | 230/4936 [07:24<3:05:09,  2.36s/it]Training:   5%|▍         | 231/4936 [07:26<2:57:47,  2.27s/it]Training:   5%|▍         | 232/4936 [07:28<2:52:02,  2.19s/it]Training:   5%|▍         | 233/4936 [07:30<2:47:58,  2.14s/it]Training:   5%|▍         | 234/4936 [07:33<2:51:23,  2.19s/it]Training:   5%|▍         | 235/4936 [07:34<2:37:35,  2.01s/it]Training:   5%|▍         | 236/4936 [07:36<2:27:47,  1.89s/it]Training:   5%|▍         | 237/4936 [07:37<2:17:11,  1.75s/it]Training:   5%|▍         | 238/4936 [07:39<2:15:21,  1.73s/it]Training:   5%|▍         | 239/4936 [07:40<2:08:43,  1.64s/it]Training:   5%|▍         | 240/4936 [07:42<2:04:50,  1.60s/it]Training:   5%|▍         | 241/4936 [07:44<2:08:16,  1.64s/it]Training:   5%|▍         | 242/4936 [07:46<2:16:29,  1.74s/it]Training:   5%|▍         | 243/4936 [07:47<2:20:59,  1.80s/it]Training:   5%|▍         | 244/4936 [07:53<3:39:09,  2.80s/it]Training:   5%|▍         | 245/4936 [07:54<3:08:40,  2.41s/it]Training:   5%|▍         | 246/4936 [07:56<2:51:30,  2.19s/it]Training:   5%|▌         | 247/4936 [07:57<2:31:55,  1.94s/it]Training:   5%|▌         | 248/4936 [07:59<2:19:42,  1.79s/it]Training:   5%|▌         | 249/4936 [08:00<2:16:58,  1.75s/it]Training:   5%|▌         | 250/4936 [08:02<2:23:09,  1.83s/it]Training:   5%|▌         | 251/4936 [08:04<2:18:40,  1.78s/it]Training:   5%|▌         | 252/4936 [08:06<2:15:43,  1.74s/it]Training:   5%|▌         | 253/4936 [08:08<2:31:53,  1.95s/it]Training:   5%|▌         | 254/4936 [08:09<2:20:28,  1.80s/it]Training:   5%|▌         | 255/4936 [08:11<2:15:23,  1.74s/it]Training:   5%|▌         | 256/4936 [08:13<2:22:09,  1.82s/it]Training:   5%|▌         | 257/4936 [08:15<2:35:53,  2.00s/it]Training:   5%|▌         | 258/4936 [08:17<2:17:03,  1.76s/it]Training:   5%|▌         | 259/4936 [08:19<2:20:50,  1.81s/it]Training:   5%|▌         | 260/4936 [08:20<2:10:31,  1.67s/it]Training:   5%|▌         | 261/4936 [08:22<2:09:47,  1.67s/it]Training:   5%|▌         | 262/4936 [08:23<2:07:49,  1.64s/it]Training:   5%|▌         | 263/4936 [08:25<2:22:39,  1.83s/it]Training:   5%|▌         | 264/4936 [08:28<2:32:47,  1.96s/it]Training:   5%|▌         | 265/4936 [08:29<2:20:33,  1.81s/it]Training:   5%|▌         | 266/4936 [08:31<2:15:22,  1.74s/it]Training:   5%|▌         | 267/4936 [08:32<2:06:17,  1.62s/it]Training:   5%|▌         | 268/4936 [08:34<2:09:03,  1.66s/it]Training:   5%|▌         | 269/4936 [08:36<2:23:09,  1.84s/it]Training:   5%|▌         | 270/4936 [08:38<2:21:08,  1.81s/it]Training:   5%|▌         | 271/4936 [08:40<2:18:08,  1.78s/it]Training:   6%|▌         | 272/4936 [08:41<2:10:20,  1.68s/it]Training:   6%|▌         | 273/4936 [08:43<2:24:18,  1.86s/it]Training:   6%|▌         | 274/4936 [08:46<2:34:02,  1.98s/it]Training:   6%|▌         | 275/4936 [08:47<2:22:45,  1.84s/it]Training:   6%|▌         | 276/4936 [08:49<2:23:33,  1.85s/it]Training:   6%|▌         | 277/4936 [08:51<2:27:45,  1.90s/it]Training:   6%|▌         | 278/4936 [08:53<2:21:37,  1.82s/it]Training:   6%|▌         | 279/4936 [08:55<2:26:04,  1.88s/it]Training:   6%|▌         | 280/4936 [08:57<2:43:26,  2.11s/it]Training:   6%|▌         | 281/4936 [09:00<3:07:43,  2.42s/it]Training:   6%|▌         | 282/4936 [09:02<2:58:24,  2.30s/it]Training:   6%|▌         | 283/4936 [09:06<3:21:58,  2.60s/it]Training:   6%|▌         | 284/4936 [09:08<3:08:24,  2.43s/it]Training:   6%|▌         | 285/4936 [09:09<2:43:09,  2.10s/it]Training:   6%|▌         | 286/4936 [09:11<2:38:53,  2.05s/it]Training:   6%|▌         | 287/4936 [09:13<2:31:55,  1.96s/it]Training:   6%|▌         | 288/4936 [09:14<2:25:14,  1.87s/it]Training:   6%|▌         | 289/4936 [09:16<2:22:15,  1.84s/it]Training:   6%|▌         | 290/4936 [09:18<2:25:50,  1.88s/it]Training:   6%|▌         | 291/4936 [09:20<2:27:20,  1.90s/it]Training:   6%|▌         | 292/4936 [09:22<2:15:01,  1.74s/it]Training:   6%|▌         | 293/4936 [09:24<2:20:31,  1.82s/it]Training:   6%|▌         | 294/4936 [09:26<2:25:28,  1.88s/it]Training:   6%|▌         | 295/4936 [09:28<2:38:12,  2.05s/it]Training:   6%|▌         | 296/4936 [09:30<2:27:41,  1.91s/it]Training:   6%|▌         | 297/4936 [09:31<2:22:27,  1.84s/it]Training:   6%|▌         | 298/4936 [09:33<2:22:58,  1.85s/it]Training:   6%|▌         | 299/4936 [09:35<2:33:49,  1.99s/it]Training:   6%|▌         | 300/4936 [09:37<2:18:41,  1.79s/it]Training:   6%|▌         | 301/4936 [09:38<2:14:46,  1.74s/it]Training:   6%|▌         | 302/4936 [09:42<2:55:17,  2.27s/it]Training:   6%|▌         | 303/4936 [09:44<2:41:21,  2.09s/it]Training:   6%|▌         | 304/4936 [09:45<2:27:15,  1.91s/it]Training:   6%|▌         | 305/4936 [09:46<2:13:51,  1.73s/it]Training:   6%|▌         | 306/4936 [09:48<2:06:55,  1.64s/it]Training:   6%|▌         | 307/4936 [09:50<2:21:32,  1.83s/it]Training:   6%|▌         | 308/4936 [09:54<2:58:36,  2.32s/it]Training:   6%|▋         | 309/4936 [09:55<2:37:08,  2.04s/it]Training:   6%|▋         | 310/4936 [09:57<2:28:41,  1.93s/it]Training:   6%|▋         | 311/4936 [09:58<2:18:29,  1.80s/it]Training:   6%|▋         | 312/4936 [10:00<2:23:31,  1.86s/it]Training:   6%|▋         | 313/4936 [10:02<2:20:58,  1.83s/it]Training:   6%|▋         | 314/4936 [10:04<2:21:58,  1.84s/it]Training:   6%|▋         | 315/4936 [10:07<2:58:47,  2.32s/it]Training:   6%|▋         | 316/4936 [10:09<2:51:40,  2.23s/it]Training:   6%|▋         | 317/4936 [10:12<2:53:54,  2.26s/it]Training:   6%|▋         | 318/4936 [10:13<2:38:38,  2.06s/it]Training:   6%|▋         | 319/4936 [10:15<2:25:19,  1.89s/it]Training:   6%|▋         | 320/4936 [10:17<2:35:03,  2.02s/it]Training:   7%|▋         | 321/4936 [10:19<2:33:53,  2.00s/it]Training:   7%|▋         | 322/4936 [10:22<3:04:22,  2.40s/it]Training:   7%|▋         | 323/4936 [10:24<2:40:50,  2.09s/it]Training:   7%|▋         | 324/4936 [10:25<2:32:40,  1.99s/it]Training:   7%|▋         | 325/4936 [10:27<2:17:35,  1.79s/it]Training:   7%|▋         | 326/4936 [10:28<2:03:20,  1.61s/it]Training:   7%|▋         | 327/4936 [10:30<2:21:55,  1.85s/it]Training:   7%|▋         | 328/4936 [10:36<3:50:52,  3.01s/it]Training:   7%|▋         | 329/4936 [10:38<3:17:37,  2.57s/it]Training:   7%|▋         | 330/4936 [10:39<2:52:30,  2.25s/it]Training:   7%|▋         | 331/4936 [10:40<2:34:52,  2.02s/it]Training:   7%|▋         | 332/4936 [10:43<2:55:41,  2.29s/it]Training:   7%|▋         | 333/4936 [10:45<2:40:15,  2.09s/it]Training:   7%|▋         | 334/4936 [10:46<2:25:13,  1.89s/it]Training:   7%|▋         | 335/4936 [10:48<2:12:14,  1.72s/it]Training:   7%|▋         | 336/4936 [10:50<2:27:46,  1.93s/it]Training:   7%|▋         | 337/4936 [10:52<2:21:40,  1.85s/it]Training:   7%|▋         | 338/4936 [10:53<2:15:23,  1.77s/it]Training:   7%|▋         | 339/4936 [10:55<2:13:11,  1.74s/it]Training:   7%|▋         | 340/4936 [10:57<2:09:51,  1.70s/it]Training:   7%|▋         | 341/4936 [10:59<2:17:05,  1.79s/it]Training:   7%|▋         | 342/4936 [11:01<2:22:44,  1.86s/it]Training:   7%|▋         | 343/4936 [11:03<2:23:09,  1.87s/it]Training:   7%|▋         | 344/4936 [11:05<2:26:26,  1.91s/it]Training:   7%|▋         | 345/4936 [11:06<2:21:10,  1.84s/it]Training:   7%|▋         | 346/4936 [11:08<2:11:58,  1.73s/it]Training:   7%|▋         | 347/4936 [11:10<2:16:39,  1.79s/it]Training:   7%|▋         | 348/4936 [11:11<2:12:08,  1.73s/it]Training:   7%|▋         | 349/4936 [11:13<2:05:22,  1.64s/it]Training:   7%|▋         | 350/4936 [11:14<2:01:33,  1.59s/it]Training:   7%|▋         | 351/4936 [11:16<2:03:19,  1.61s/it]Training:   7%|▋         | 352/4936 [11:17<1:57:32,  1.54s/it]Training:   7%|▋         | 353/4936 [11:19<1:58:50,  1.56s/it]Training:   7%|▋         | 354/4936 [11:21<2:03:15,  1.61s/it]Training:   7%|▋         | 355/4936 [11:25<3:00:41,  2.37s/it]Training:   7%|▋         | 356/4936 [11:26<2:46:01,  2.18s/it]Training:   7%|▋         | 357/4936 [11:28<2:27:09,  1.93s/it]Training:   7%|▋         | 358/4936 [11:31<2:55:00,  2.29s/it]Training:   7%|▋         | 359/4936 [11:34<3:03:25,  2.40s/it]Training:   7%|▋         | 360/4936 [11:36<3:07:08,  2.45s/it]Training:   7%|▋         | 361/4936 [11:38<2:41:45,  2.12s/it]Training:   7%|▋         | 362/4936 [11:39<2:37:05,  2.06s/it]Training:   7%|▋         | 363/4936 [11:41<2:28:14,  1.95s/it]Training:   7%|▋         | 364/4936 [11:45<3:07:40,  2.46s/it]Training:   7%|▋         | 365/4936 [11:46<2:48:40,  2.21s/it]Training:   7%|▋         | 366/4936 [11:48<2:38:00,  2.07s/it]Training:   7%|▋         | 367/4936 [11:51<2:52:15,  2.26s/it]Training:   7%|▋         | 368/4936 [11:54<3:01:42,  2.39s/it]Training:   7%|▋         | 369/4936 [11:55<2:43:48,  2.15s/it]Training:   7%|▋         | 370/4936 [11:57<2:38:54,  2.09s/it]Training:   8%|▊         | 371/4936 [11:59<2:37:17,  2.07s/it]Training:   8%|▊         | 372/4936 [12:01<2:28:22,  1.95s/it]Training:   8%|▊         | 373/4936 [12:03<2:42:07,  2.13s/it]Training:   8%|▊         | 374/4936 [12:06<2:45:47,  2.18s/it]Training:   8%|▊         | 375/4936 [12:07<2:34:26,  2.03s/it]Training:   8%|▊         | 376/4936 [12:09<2:21:51,  1.87s/it]Training:   8%|▊         | 377/4936 [12:11<2:24:39,  1.90s/it]Training:   8%|▊         | 378/4936 [12:13<2:21:08,  1.86s/it]Training:   8%|▊         | 379/4936 [12:14<2:15:04,  1.78s/it]Training:   8%|▊         | 380/4936 [12:16<2:12:51,  1.75s/it]Training:   8%|▊         | 381/4936 [12:17<2:06:39,  1.67s/it]Training:   8%|▊         | 382/4936 [12:19<2:06:59,  1.67s/it]Training:   8%|▊         | 383/4936 [12:20<2:02:31,  1.61s/it]Training:   8%|▊         | 384/4936 [12:23<2:21:52,  1.87s/it]Training:   8%|▊         | 385/4936 [12:24<2:09:55,  1.71s/it]Training:   8%|▊         | 386/4936 [12:26<2:10:32,  1.72s/it]Training:   8%|▊         | 387/4936 [12:29<2:30:56,  1.99s/it]Training:   8%|▊         | 388/4936 [12:31<2:28:33,  1.96s/it]Training:   8%|▊         | 389/4936 [12:33<2:35:21,  2.05s/it]Training:   8%|▊         | 390/4936 [12:37<3:13:32,  2.55s/it]Training:   8%|▊         | 391/4936 [12:38<2:52:23,  2.28s/it]Training:   8%|▊         | 392/4936 [12:40<2:36:51,  2.07s/it]Training:   8%|▊         | 393/4936 [12:42<2:35:41,  2.06s/it]Training:   8%|▊         | 394/4936 [12:44<2:31:36,  2.00s/it]Training:   8%|▊         | 395/4936 [12:45<2:25:59,  1.93s/it]Training:   8%|▊         | 396/4936 [12:47<2:18:11,  1.83s/it]Training:   8%|▊         | 397/4936 [12:49<2:14:56,  1.78s/it]Training:   8%|▊         | 398/4936 [12:51<2:25:38,  1.93s/it]Training:   8%|▊         | 399/4936 [12:52<2:13:01,  1.76s/it]Training:   8%|▊         | 400/4936 [12:55<2:25:30,  1.92s/it]Training:   8%|▊         | 401/4936 [12:56<2:19:06,  1.84s/it]Training:   8%|▊         | 402/4936 [12:58<2:15:20,  1.79s/it]Training:   8%|▊         | 403/4936 [12:59<2:07:18,  1.69s/it]Training:   8%|▊         | 404/4936 [13:01<2:08:44,  1.70s/it]Training:   8%|▊         | 405/4936 [13:04<2:24:45,  1.92s/it]Training:   8%|▊         | 406/4936 [13:05<2:21:21,  1.87s/it]Training:   8%|▊         | 407/4936 [13:07<2:15:02,  1.79s/it]Training:   8%|▊         | 408/4936 [13:08<2:05:23,  1.66s/it]Training:   8%|▊         | 409/4936 [13:10<2:03:33,  1.64s/it]Training:   8%|▊         | 410/4936 [13:12<2:17:31,  1.82s/it]Training:   8%|▊         | 411/4936 [13:14<2:14:23,  1.78s/it]Training:   8%|▊         | 412/4936 [13:16<2:26:33,  1.94s/it]Training:   8%|▊         | 413/4936 [13:18<2:22:17,  1.89s/it]Training:   8%|▊         | 414/4936 [13:19<2:10:31,  1.73s/it]Training:   8%|▊         | 415/4936 [13:21<2:09:07,  1.71s/it]Training:   8%|▊         | 416/4936 [13:22<2:01:14,  1.61s/it]Training:   8%|▊         | 417/4936 [13:24<2:10:14,  1.73s/it]Training:   8%|▊         | 418/4936 [13:26<2:13:39,  1.77s/it]Training:   8%|▊         | 419/4936 [13:28<2:19:15,  1.85s/it]Training:   9%|▊         | 420/4936 [13:30<2:13:24,  1.77s/it]Training:   9%|▊         | 421/4936 [13:31<2:10:09,  1.73s/it]Training:   9%|▊         | 422/4936 [13:34<2:28:16,  1.97s/it]Training:   9%|▊         | 423/4936 [13:36<2:36:22,  2.08s/it]Training:   9%|▊         | 424/4936 [13:38<2:25:20,  1.93s/it]Training:   9%|▊         | 425/4936 [13:39<2:15:06,  1.80s/it]Training:   9%|▊         | 426/4936 [13:41<2:14:00,  1.78s/it]Training:   9%|▊         | 427/4936 [13:43<2:18:29,  1.84s/it]Training:   9%|▊         | 428/4936 [13:46<2:34:24,  2.06s/it]Training:   9%|▊         | 429/4936 [13:47<2:24:04,  1.92s/it]Training:   9%|▊         | 430/4936 [13:49<2:18:04,  1.84s/it]Training:   9%|▊         | 431/4936 [13:51<2:33:38,  2.05s/it]Training:   9%|▉         | 432/4936 [13:53<2:31:41,  2.02s/it]Training:   9%|▉         | 433/4936 [13:55<2:28:14,  1.98s/it]Training:   9%|▉         | 434/4936 [13:57<2:19:37,  1.86s/it]Training:   9%|▉         | 435/4936 [13:58<2:13:27,  1.78s/it]Training:   9%|▉         | 436/4936 [14:01<2:33:52,  2.05s/it]Training:   9%|▉         | 437/4936 [14:02<2:18:35,  1.85s/it]Training:   9%|▉         | 438/4936 [14:04<2:14:06,  1.79s/it]Training:   9%|▉         | 439/4936 [14:06<2:07:20,  1.70s/it]Training:   9%|▉         | 440/4936 [14:07<2:02:13,  1.63s/it]Training:   9%|▉         | 441/4936 [14:09<2:01:02,  1.62s/it]Training:   9%|▉         | 442/4936 [14:11<2:18:41,  1.85s/it]Training:   9%|▉         | 443/4936 [14:13<2:14:11,  1.79s/it]Training:   9%|▉         | 444/4936 [14:14<2:07:11,  1.70s/it]Training:   9%|▉         | 445/4936 [14:16<2:06:39,  1.69s/it]Training:   9%|▉         | 446/4936 [14:17<2:04:22,  1.66s/it]Training:   9%|▉         | 447/4936 [14:19<2:11:26,  1.76s/it]Training:   9%|▉         | 448/4936 [14:21<2:09:58,  1.74s/it]Training:   9%|▉         | 449/4936 [14:23<2:08:16,  1.72s/it]Training:   9%|▉         | 450/4936 [14:25<2:13:12,  1.78s/it]Training:   9%|▉         | 451/4936 [14:26<2:12:19,  1.77s/it]Training:   9%|▉         | 452/4936 [14:28<2:05:48,  1.68s/it]Training:   9%|▉         | 453/4936 [14:30<2:22:19,  1.90s/it]Training:   9%|▉         | 454/4936 [14:32<2:12:08,  1.77s/it]Training:   9%|▉         | 455/4936 [14:33<2:08:02,  1.71s/it]Training:   9%|▉         | 456/4936 [14:35<2:13:50,  1.79s/it]Training:   9%|▉         | 457/4936 [14:37<2:15:46,  1.82s/it]Training:   9%|▉         | 458/4936 [14:40<2:26:03,  1.96s/it]Training:   9%|▉         | 459/4936 [14:41<2:21:25,  1.90s/it]Training:   9%|▉         | 460/4936 [14:43<2:18:16,  1.85s/it]Training:   9%|▉         | 461/4936 [14:45<2:09:51,  1.74s/it]Training:   9%|▉         | 462/4936 [14:46<2:12:31,  1.78s/it]Training:   9%|▉         | 463/4936 [14:48<2:15:50,  1.82s/it]Training:   9%|▉         | 464/4936 [14:50<2:12:36,  1.78s/it]Training:   9%|▉         | 465/4936 [14:51<2:05:57,  1.69s/it]Training:   9%|▉         | 466/4936 [14:53<2:00:27,  1.62s/it]Training:   9%|▉         | 467/4936 [14:55<2:03:07,  1.65s/it]Training:   9%|▉         | 468/4936 [14:56<1:59:20,  1.60s/it]Training:  10%|▉         | 469/4936 [14:58<2:05:18,  1.68s/it]Training:  10%|▉         | 470/4936 [15:00<2:03:23,  1.66s/it]Training:  10%|▉         | 471/4936 [15:01<1:56:33,  1.57s/it]Training:  10%|▉         | 472/4936 [15:03<1:56:59,  1.57s/it]Training:  10%|▉         | 473/4936 [15:04<1:58:25,  1.59s/it]Training:  10%|▉         | 474/4936 [15:06<1:55:03,  1.55s/it]Training:  10%|▉         | 475/4936 [15:07<1:46:45,  1.44s/it]Training:  10%|▉         | 476/4936 [15:09<2:11:08,  1.76s/it]Training:  10%|▉         | 477/4936 [15:11<2:17:09,  1.85s/it]Training:  10%|▉         | 478/4936 [15:13<2:09:09,  1.74s/it]Training:  10%|▉         | 479/4936 [15:14<2:06:38,  1.70s/it]Training:  10%|▉         | 480/4936 [15:16<2:07:36,  1.72s/it]Training:  10%|▉         | 481/4936 [15:18<2:10:56,  1.76s/it]Training:  10%|▉         | 482/4936 [15:20<2:10:37,  1.76s/it]Training:  10%|▉         | 483/4936 [15:21<2:07:48,  1.72s/it]Training:  10%|▉         | 484/4936 [15:25<2:45:48,  2.23s/it]Training:  10%|▉         | 485/4936 [15:27<2:41:55,  2.18s/it]Training:  10%|▉         | 486/4936 [15:30<2:50:01,  2.29s/it]Training:  10%|▉         | 487/4936 [15:31<2:36:20,  2.11s/it]Training:  10%|▉         | 488/4936 [15:34<2:46:16,  2.24s/it]Training:  10%|▉         | 489/4936 [15:36<2:50:08,  2.30s/it]Training:  10%|▉         | 490/4936 [15:38<2:36:53,  2.12s/it]Training:  10%|▉         | 491/4936 [15:40<2:26:11,  1.97s/it]Training:  10%|▉         | 492/4936 [15:42<2:41:40,  2.18s/it]Training:  10%|▉         | 493/4936 [15:46<3:25:45,  2.78s/it]Training:  10%|█         | 494/4936 [15:48<3:03:56,  2.48s/it]Training:  10%|█         | 495/4936 [15:51<3:07:03,  2.53s/it]Training:  10%|█         | 495/4936 [15:51<2:22:15,  1.92s/it]
Traceback (most recent call last):
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/main.py", line 71, in <module>
    main()
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/main.py", line 68, in main
    args.func(args)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/training.py", line 127, in train
    return crossval(args, fn)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/training.py", line 92, in crossval
    metrics = fn(args, fold)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/training.py", line 261, in train_lmkt
    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc="Training")):
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 788, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/vqchen_umass_edu/.conda/envs/LLMKT/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/home/vqchen_umass_edu/dialogue-kt/dialogue_kt/kt_data_loading.py", line 188, in __call__
    "labels": to_device(torch.Tensor([sample["label"] for sample in batch]), device, self.args),
ValueError: too many dimensions 'str'
